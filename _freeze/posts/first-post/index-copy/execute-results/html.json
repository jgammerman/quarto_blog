{
  "hash": "a98bcda15fde9327a5d5f725837be92d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Text Classification with LLMs (part 1)\"\ndescription: \"TODO\"\nauthor: \"James Gammerman\"\ndate: \"10/29/2024\"\ndraft: false\nformat:\n  html:\n    code-fold: false\njupyter: thellmbook\nexecute:\n    cache: true\n    kernel: thellmbook\n    # python: /Users/yasha/miniconda3/envs/thellmbook/bin/python\nbiblioraphy: references.bib\n---\n\n\n\n\n\n# Introduction\n\nHello! And welcome to my first blog post.\n\nI'm currently reading the excellent [Hands-On Large Language Models](https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/) book by Jay Alammar and Maarten Grootendorst. In order to get the most out of these kinds of books, I find it's best to take the code in them and then adapt it to new data. So in that spirit, I'm going to do my own version of Chapter 4 in the book, which is all about text classification.\n\nThere are many different kinds of LLM. Broadly speaking we can put them into two categories:\n\n-   Representation LLMs\n-   Generative LLMs\n\n*Representation models* focus on understanding and representing the meaning of text. They work by converting input text into an embedding (i.e. a dense vector representation) that captures its semantic information. The generated embeddings are then fed into a separate classifier to predict a class label. So you can think of it as a two-step process: firstly encode the text into a meaningful representation, then classify it. These models are encoder-only, and notable examples include BERT, RoBERTa and sentence-BERT.\n\n*Generative models* focus on generating text. They are trained to predict the next word in a sequence, whicih is similar in style and content to the training data. They can be adapted for classification by providign them with a carefully designed prompt that guides them to generate a specific output corresponding to the class label. They are decoder-only or encoder-decoder models, and notable examples include the GPT family (including ChatGPT), Flan-T5 and the image generation model DALL-E.\n\nThe difference between the two is shown in @fig:rep-vs-gen-models.\n\n![Both representation and generative models can be used for classification, but they take different approaches](images/rep-models-vs-gen-models.jpg){#fig:rep-vs-gen-models}\n\nThe dataset we will use is the **Amazon Polarity Dataset**. This dataset contains reviews from Amazon, categorized as either positive or negative sentiment. Each entry consists of a title, the review text, and the associated sentiment label, making it an excellent dataset for training and evaluating sentiment classification models.\n\n::: {#load-data .cell cache='true' execution_count=2}\n``` {.python .cell-code}\nfrom datasets import load_dataset\n\n# Load our data\ndata = load_dataset(\"amazon_polarity\")\n\n# Take a random sample of 10k training examples and 2k test examples\ntrain_sample = data[\"train\"].shuffle(seed=42).select(range(10000))\ntest_sample = data[\"test\"].shuffle(seed=42).select(range(2000))\n```\n:::\n\n\n::: {#e783caf6 .cell cache='true' execution_count=3}\n``` {.python .cell-code}\n# ## Value Counts for Labels in the Training Set\n# To better understand our dataset, let's count how many positive and negative labels we have in the training set.\nfrom collections import Counter\n\n# Count the number of occurrences of each label in the training and test data\nlabel_counts = Counter(train_sample[\"label\"])\nprint(f\"Label Counts in Training Set: {label_counts}\")\nlabel_counts = Counter(test_sample[\"label\"])\nprint(f\"Label Counts in Test Set: {label_counts}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLabel Counts in Training Set: Counter({0: 5003, 1: 4997})\nLabel Counts in Test Set: Counter({1: 1018, 0: 982})\n```\n:::\n:::\n\n\n```         \nLabel Counts in Training Set: Counter({0: 5003, 1: 4997})\n```\n\n::: {#40947ab3 .cell cache='true' execution_count=4}\n``` {.python .cell-code}\n# Let's take a quick look at a couple of examples from our dataset to understand its structure.\nprint(train_sample[0])\nprint(train_sample[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'label': 0, 'title': 'Anyone who likes this better than the Pekinpah is a moron.', 'content': \"All the pretty people in this film. Even the Rudy character played by Michael Madsen. This is adapted from a Jim Thompson novel for cryin' out loud! These are supposed to be marginal characters, not fashion models. Though McQueen and McGraw were attractive (but check out McQueen's crummy prison haircut) they were believable in the role. Baldwin and Bassinger seem like movie stars trying to act like hard cases. Action wise, the robbery scene in the Pekinpah version was about 100 times more exciting and suspenseful than anything in this re-make.\"}\n{'label': 0, 'title': 'Author seems mentally unstable', 'content': 'I know that Tom Robbins has a loyal following and I started the book with high expectations. However, I did not enjoy this book as it was too much work to follow his confused logic. I think that he was under the influence during most of time that he wrote.'}\n```\n:::\n:::\n\n\n# Text Classification with Representation-Based Models\n\nNow that we have an idea of what our data looks like, we can proceed to load a pre-trained Transformer model for text classification.\n\nWe will use a model from the Hugging Face Transformers library, which provides state-of-the-art performance for various NLP tasks.\n\n::: {#load-representation-model .cell cache='true' execution_count=5}\n``` {.python .cell-code}\n# Import the pipeline function from the transformers library\nfrom transformers import pipeline\n# import torch\n\n# Here, we use a sentiment analysis model from Hugging Face's model hub that is specifically designed for binary sentiment analysis.\nmodel_path = \"distilbert-base-uncased-finetuned-sst-2-english\"\n# model_path = \"distilbert-base-uncased\" \n\n# Use GPU if available, otherwise fallback to CPU\n# device = 0 if torch.cuda.is_available() else -1\n\n# Load the model into a pipeline for easy inference\npipe = pipeline(\n    model=model_path,\n    tokenizer=model_path,\n    # return_all_scores=True,\n    top_k=None,\n    device=-1\n)\n```\n:::\n\n\n::: {#e80abd52 .cell execution_count=6}\n``` {.python .cell-code}\nprint(pipe)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<transformers.pipelines.text_classification.TextClassificationPipeline object at 0x1ba39b2e0>\n```\n:::\n:::\n\n\n# Running Sentiment Analysis on Sample Data\n\nLet's use the loaded model to classify some sample reviews from our dataset.\n\nWe'll run the model on a few reviews to see how well it predicts the sentiment.\n\n::: {#614d55b4 .cell cache='true' execution_count=7}\n``` {.python .cell-code}\n# Test with a basic string input\nresult = pipe(\"I love this product! It's fantastic.\")\nprint(f\"Sentiment Analysis Result: {result}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSentiment Analysis Result: [[{'label': 'POSITIVE', 'score': 0.9998825788497925}, {'label': 'NEGATIVE', 'score': 0.00011738832108676434}]]\n```\n:::\n:::\n\n\n::: {#7221d9e6 .cell cache='true' execution_count=8}\n``` {.python .cell-code}\n# Run sentiment analysis on the first review\n# sample_review = data[\"train\"][0][\"content\"]\nsample_review = train_sample[0][\"content\"]\n\nresult = pipe(sample_review)\nprint(f\"Review: {sample_review}\")\nprint(f\"Sentiment Analysis Result: {result}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReview: All the pretty people in this film. Even the Rudy character played by Michael Madsen. This is adapted from a Jim Thompson novel for cryin' out loud! These are supposed to be marginal characters, not fashion models. Though McQueen and McGraw were attractive (but check out McQueen's crummy prison haircut) they were believable in the role. Baldwin and Bassinger seem like movie stars trying to act like hard cases. Action wise, the robbery scene in the Pekinpah version was about 100 times more exciting and suspenseful than anything in this re-make.\nSentiment Analysis Result: [[{'label': 'POSITIVE', 'score': 0.9834295511245728}, {'label': 'NEGATIVE', 'score': 0.016570482403039932}]]\n```\n:::\n:::\n\n\n```         \nReview: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\nSentiment Analysis Result: [[{'label': 'NEGATIVE', 'score': 0.0008272510604001582}, {'label': 'POSITIVE', 'score': 0.9991727471351624}]]\n```\n\n\\# Evaluating the Model Performance\n\n::: {#make-predictions .cell cache='true' execution_count=9}\n``` {.python .cell-code}\n# Import necessary libraries\nimport numpy as np\nfrom tqdm import tqdm\nfrom transformers.pipelines.pt_utils import KeyDataset  # Imports KeyDataset from transformers for efficient data loading\n\n# Run inference - This section performs the prediction process\ny_pred = []  # Initializes an empty list to store the predictions\n\n# Iterate through the test data using tqdm for a progress bar\nfor output in tqdm(pipe(KeyDataset(test_sample, \"content\"), batch_size=8), total=len(test_sample)):\n    # Extract negative and positive sentiment scores from the pipeline's output\n    negative_score = output[0][\"score\"]\n    positive_score = output[1][\"score\"]\n    assignment = np.argmax([negative_score, positive_score])  # Determines the predicted class (0 for negative, 1 for positive)\n    y_pred.append(assignment)  # Appends the predicted class to the y_pred list\n\n# Display the first 10 predictions\nprint(f\"First 10 Predictions: {y_pred[:10]}\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/2000 [00:00<?, ?it/s]\r  0%|          | 1/2000 [00:00<26:35,  1.25it/s]\r  0%|          | 9/2000 [00:01<03:59,  8.30it/s]\r  1%|          | 17/2000 [00:01<02:24, 13.72it/s]\r  1%|▏         | 25/2000 [00:01<01:54, 17.19it/s]\r  2%|▏         | 33/2000 [00:02<01:50, 17.87it/s]\r  2%|▏         | 41/2000 [00:02<02:01, 16.12it/s]\r  2%|▏         | 49/2000 [00:03<01:48, 17.95it/s]\r  3%|▎         | 57/2000 [00:03<01:54, 16.91it/s]\r  3%|▎         | 65/2000 [00:04<01:48, 17.75it/s]\r  4%|▎         | 73/2000 [00:04<01:48, 17.75it/s]\r  4%|▍         | 81/2000 [00:05<01:51, 17.28it/s]\r  4%|▍         | 89/2000 [00:05<01:53, 16.91it/s]\r  5%|▍         | 97/2000 [00:06<01:52, 16.90it/s]\r  5%|▌         | 105/2000 [00:06<01:46, 17.83it/s]\r  6%|▌         | 113/2000 [00:07<01:53, 16.69it/s]\r  6%|▌         | 121/2000 [00:07<01:51, 16.92it/s]\r  6%|▋         | 129/2000 [00:07<01:40, 18.63it/s]\r  7%|▋         | 137/2000 [00:08<01:40, 18.57it/s]\r  7%|▋         | 145/2000 [00:08<01:43, 17.84it/s]\r  8%|▊         | 153/2000 [00:09<01:45, 17.52it/s]\r  8%|▊         | 161/2000 [00:09<01:36, 19.05it/s]\r  8%|▊         | 169/2000 [00:09<01:32, 19.72it/s]\r  9%|▉         | 177/2000 [00:10<01:29, 20.32it/s]\r  9%|▉         | 185/2000 [00:10<01:32, 19.53it/s]\r 10%|▉         | 193/2000 [00:11<01:39, 18.08it/s]\r 10%|█         | 201/2000 [00:11<01:41, 17.66it/s]\r 10%|█         | 209/2000 [00:12<01:35, 18.82it/s]\r 11%|█         | 217/2000 [00:12<01:32, 19.24it/s]\r 11%|█▏        | 225/2000 [00:12<01:27, 20.36it/s]\r 12%|█▏        | 233/2000 [00:13<01:25, 20.64it/s]\r 12%|█▏        | 241/2000 [00:13<01:30, 19.47it/s]\r 12%|█▏        | 249/2000 [00:14<01:37, 17.87it/s]\r 13%|█▎        | 257/2000 [00:14<01:37, 17.93it/s]\r 13%|█▎        | 265/2000 [00:14<01:30, 19.24it/s]\r 14%|█▎        | 273/2000 [00:15<01:37, 17.72it/s]\r 14%|█▍        | 281/2000 [00:16<01:42, 16.73it/s]\r 14%|█▍        | 289/2000 [00:16<01:37, 17.49it/s]\r 15%|█▍        | 297/2000 [00:16<01:27, 19.49it/s]\r 15%|█▌        | 305/2000 [00:17<01:33, 18.11it/s]\r 16%|█▌        | 313/2000 [00:17<01:36, 17.48it/s]\r 16%|█▌        | 321/2000 [00:18<01:25, 19.70it/s]\r 16%|█▋        | 329/2000 [00:18<01:24, 19.67it/s]\r 17%|█▋        | 337/2000 [00:18<01:23, 19.84it/s]\r 17%|█▋        | 345/2000 [00:19<01:22, 20.00it/s]\r 18%|█▊        | 353/2000 [00:19<01:20, 20.57it/s]\r 18%|█▊        | 361/2000 [00:20<01:38, 16.70it/s]\r 18%|█▊        | 369/2000 [00:20<01:28, 18.34it/s]\r 19%|█▉        | 377/2000 [00:21<01:28, 18.33it/s]\r 19%|█▉        | 385/2000 [00:21<01:31, 17.58it/s]\r 20%|█▉        | 393/2000 [00:22<01:38, 16.37it/s]\r 20%|██        | 401/2000 [00:22<01:36, 16.61it/s]\r 20%|██        | 409/2000 [00:23<01:36, 16.48it/s]\r 21%|██        | 417/2000 [00:23<01:43, 15.33it/s]\r 21%|██▏       | 425/2000 [00:24<01:41, 15.51it/s]\r 22%|██▏       | 433/2000 [00:24<01:35, 16.44it/s]\r 22%|██▏       | 441/2000 [00:25<01:28, 17.65it/s]\r 22%|██▏       | 449/2000 [00:25<01:27, 17.70it/s]\r 23%|██▎       | 457/2000 [00:25<01:29, 17.17it/s]\r 23%|██▎       | 465/2000 [00:26<01:28, 17.25it/s]\r 24%|██▎       | 473/2000 [00:26<01:34, 16.17it/s]\r 24%|██▍       | 481/2000 [00:27<01:39, 15.25it/s]\r 24%|██▍       | 489/2000 [00:28<01:46, 14.17it/s]\r 25%|██▍       | 497/2000 [00:28<01:39, 15.05it/s]\r 25%|██▌       | 505/2000 [00:29<01:39, 15.04it/s]\r 26%|██▌       | 513/2000 [00:29<01:40, 14.78it/s]\r 26%|██▌       | 521/2000 [00:30<01:38, 15.01it/s]\r 26%|██▋       | 529/2000 [00:31<01:48, 13.60it/s]\r 27%|██▋       | 537/2000 [00:31<01:53, 12.91it/s]\r 27%|██▋       | 545/2000 [00:32<01:51, 13.09it/s]\r 28%|██▊       | 553/2000 [00:33<02:00, 12.00it/s]\r 28%|██▊       | 561/2000 [00:33<01:53, 12.62it/s]\r 28%|██▊       | 569/2000 [00:34<02:03, 11.61it/s]\r 29%|██▉       | 577/2000 [00:35<01:56, 12.17it/s]\r 29%|██▉       | 585/2000 [00:35<01:48, 13.06it/s]\r 30%|██▉       | 593/2000 [00:36<01:51, 12.67it/s]\r 30%|███       | 601/2000 [00:36<01:50, 12.68it/s]\r 30%|███       | 609/2000 [00:37<01:44, 13.35it/s]\r 31%|███       | 617/2000 [00:37<01:43, 13.41it/s]\r 31%|███▏      | 625/2000 [00:38<01:29, 15.40it/s]\r 32%|███▏      | 633/2000 [00:39<01:37, 13.99it/s]\r 32%|███▏      | 641/2000 [00:39<01:38, 13.78it/s]\r 32%|███▏      | 649/2000 [00:40<01:52, 12.03it/s]\r 33%|███▎      | 657/2000 [00:41<01:52, 11.96it/s]\r 33%|███▎      | 665/2000 [00:41<01:48, 12.27it/s]\r 34%|███▎      | 673/2000 [00:42<01:37, 13.59it/s]\r 34%|███▍      | 681/2000 [00:42<01:34, 13.92it/s]\r 34%|███▍      | 689/2000 [00:43<01:39, 13.17it/s]\r 35%|███▍      | 697/2000 [00:44<01:43, 12.60it/s]\r 35%|███▌      | 705/2000 [00:44<01:49, 11.80it/s]\r 36%|███▌      | 713/2000 [00:45<01:48, 11.82it/s]\r 36%|███▌      | 721/2000 [00:46<01:48, 11.81it/s]\r 36%|███▋      | 729/2000 [00:47<01:50, 11.47it/s]\r 37%|███▋      | 737/2000 [00:47<01:40, 12.53it/s]\r 37%|███▋      | 745/2000 [00:48<01:35, 13.08it/s]\r 38%|███▊      | 753/2000 [00:48<01:29, 13.87it/s]\r 38%|███▊      | 761/2000 [00:48<01:17, 15.99it/s]\r 38%|███▊      | 769/2000 [00:49<01:13, 16.79it/s]\r 39%|███▉      | 777/2000 [00:49<01:05, 18.72it/s]\r 39%|███▉      | 785/2000 [00:50<01:13, 16.44it/s]\r 40%|███▉      | 793/2000 [00:50<01:05, 18.29it/s]\r 40%|████      | 801/2000 [00:51<01:13, 16.33it/s]\r 40%|████      | 809/2000 [00:51<01:09, 17.26it/s]\r 41%|████      | 817/2000 [00:52<01:08, 17.23it/s]\r 41%|████▏     | 825/2000 [00:52<01:13, 16.01it/s]\r 42%|████▏     | 833/2000 [00:52<01:06, 17.65it/s]\r 42%|████▏     | 841/2000 [00:53<01:07, 17.20it/s]\r 42%|████▏     | 849/2000 [00:54<01:10, 16.40it/s]\r 43%|████▎     | 857/2000 [00:54<01:05, 17.35it/s]\r 43%|████▎     | 865/2000 [00:54<01:02, 18.06it/s]\r 44%|████▎     | 873/2000 [00:55<01:05, 17.15it/s]\r 44%|████▍     | 881/2000 [00:56<01:18, 14.19it/s]\r 44%|████▍     | 889/2000 [00:56<01:07, 16.52it/s]\r 45%|████▍     | 897/2000 [00:56<01:07, 16.36it/s]\r 45%|████▌     | 905/2000 [00:57<01:05, 16.59it/s]\r 46%|████▌     | 913/2000 [00:57<01:03, 17.24it/s]\r 46%|████▌     | 921/2000 [00:58<01:04, 16.65it/s]\r 46%|████▋     | 929/2000 [00:58<01:09, 15.36it/s]\r 47%|████▋     | 937/2000 [00:59<01:05, 16.21it/s]\r 47%|████▋     | 945/2000 [01:00<01:10, 14.89it/s]\r 48%|████▊     | 953/2000 [01:00<01:10, 14.91it/s]\r 48%|████▊     | 961/2000 [01:01<01:09, 15.04it/s]\r 48%|████▊     | 969/2000 [01:01<01:05, 15.83it/s]\r 49%|████▉     | 977/2000 [01:01<01:01, 16.67it/s]\r 49%|████▉     | 985/2000 [01:02<01:02, 16.14it/s]\r 50%|████▉     | 993/2000 [01:03<01:06, 15.14it/s]\r 50%|█████     | 1001/2000 [01:03<01:06, 14.92it/s]\r 50%|█████     | 1009/2000 [01:04<01:05, 15.24it/s]\r 51%|█████     | 1017/2000 [01:04<01:02, 15.75it/s]\r 51%|█████▏    | 1025/2000 [01:05<01:04, 15.05it/s]\r 52%|█████▏    | 1033/2000 [01:05<01:05, 14.86it/s]\r 52%|█████▏    | 1041/2000 [01:06<00:57, 16.54it/s]\r 52%|█████▏    | 1049/2000 [01:06<01:01, 15.47it/s]\r 53%|█████▎    | 1057/2000 [01:07<01:09, 13.53it/s]\r 53%|█████▎    | 1065/2000 [01:07<01:03, 14.61it/s]\r 54%|█████▎    | 1073/2000 [01:08<00:55, 16.68it/s]\r 54%|█████▍    | 1081/2000 [01:08<00:56, 16.16it/s]\r 54%|█████▍    | 1089/2000 [01:09<00:54, 16.79it/s]\r 55%|█████▍    | 1097/2000 [01:09<01:01, 14.63it/s]\r 55%|█████▌    | 1105/2000 [01:10<00:55, 16.03it/s]\r 56%|█████▌    | 1113/2000 [01:10<00:51, 17.32it/s]\r 56%|█████▌    | 1121/2000 [01:11<00:53, 16.52it/s]\r 56%|█████▋    | 1129/2000 [01:11<00:50, 17.41it/s]\r 57%|█████▋    | 1137/2000 [01:12<00:48, 17.74it/s]\r 57%|█████▋    | 1145/2000 [01:12<00:47, 17.95it/s]\r 58%|█████▊    | 1153/2000 [01:12<00:46, 18.21it/s]\r 58%|█████▊    | 1161/2000 [01:13<00:49, 16.80it/s]\r 58%|█████▊    | 1169/2000 [01:13<00:46, 17.69it/s]\r 59%|█████▉    | 1177/2000 [01:14<00:45, 17.93it/s]\r 59%|█████▉    | 1185/2000 [01:14<00:46, 17.43it/s]\r 60%|█████▉    | 1193/2000 [01:15<00:49, 16.22it/s]\r 60%|██████    | 1201/2000 [01:15<00:50, 15.93it/s]\r 60%|██████    | 1209/2000 [01:16<00:51, 15.38it/s]\r 61%|██████    | 1217/2000 [01:16<00:44, 17.71it/s]\r 61%|██████▏   | 1225/2000 [01:17<00:44, 17.43it/s]\r 62%|██████▏   | 1233/2000 [01:17<00:45, 16.94it/s]\r 62%|██████▏   | 1241/2000 [01:18<00:47, 15.94it/s]\r 62%|██████▏   | 1249/2000 [01:18<00:45, 16.49it/s]\r 63%|██████▎   | 1257/2000 [01:19<00:46, 16.00it/s]\r 63%|██████▎   | 1265/2000 [01:19<00:43, 16.88it/s]\r 64%|██████▎   | 1273/2000 [01:20<00:44, 16.42it/s]\r 64%|██████▍   | 1281/2000 [01:20<00:44, 16.26it/s]\r 64%|██████▍   | 1289/2000 [01:21<00:48, 14.68it/s]\r 65%|██████▍   | 1297/2000 [01:21<00:42, 16.56it/s]\r 65%|██████▌   | 1305/2000 [01:22<00:39, 17.66it/s]\r 66%|██████▌   | 1313/2000 [01:22<00:38, 18.04it/s]\r 66%|██████▌   | 1321/2000 [01:23<00:41, 16.48it/s]\r 66%|██████▋   | 1329/2000 [01:23<00:38, 17.52it/s]\r 67%|██████▋   | 1337/2000 [01:23<00:38, 17.35it/s]\r 67%|██████▋   | 1345/2000 [01:24<00:32, 20.05it/s]\r 68%|██████▊   | 1353/2000 [01:24<00:34, 19.02it/s]\r 68%|██████▊   | 1361/2000 [01:25<00:35, 18.11it/s]\r 68%|██████▊   | 1369/2000 [01:25<00:34, 18.17it/s]\r 69%|██████▉   | 1377/2000 [01:26<00:34, 18.25it/s]\r 69%|██████▉   | 1385/2000 [01:26<00:38, 16.01it/s]\r 70%|██████▉   | 1393/2000 [01:27<00:36, 16.78it/s]\r 70%|███████   | 1401/2000 [01:27<00:32, 18.44it/s]\r 70%|███████   | 1409/2000 [01:27<00:35, 16.77it/s]\r 71%|███████   | 1417/2000 [01:28<00:33, 17.24it/s]\r 71%|███████▏  | 1425/2000 [01:28<00:33, 16.97it/s]\r 72%|███████▏  | 1433/2000 [01:29<00:35, 16.10it/s]\r 72%|███████▏  | 1441/2000 [01:29<00:34, 16.15it/s]\r 72%|███████▏  | 1449/2000 [01:30<00:37, 14.86it/s]\r 73%|███████▎  | 1457/2000 [01:31<00:35, 15.34it/s]\r 73%|███████▎  | 1465/2000 [01:31<00:32, 16.68it/s]\r 74%|███████▎  | 1473/2000 [01:32<00:32, 16.00it/s]\r 74%|███████▍  | 1481/2000 [01:32<00:31, 16.50it/s]\r 74%|███████▍  | 1489/2000 [01:32<00:29, 17.05it/s]\r 75%|███████▍  | 1497/2000 [01:33<00:29, 17.19it/s]\r 75%|███████▌  | 1505/2000 [01:33<00:28, 17.27it/s]\r 76%|███████▌  | 1513/2000 [01:34<00:29, 16.49it/s]\r 76%|███████▌  | 1521/2000 [01:34<00:29, 16.49it/s]\r 76%|███████▋  | 1529/2000 [01:35<00:30, 15.54it/s]\r 77%|███████▋  | 1537/2000 [01:35<00:28, 16.29it/s]\r 77%|███████▋  | 1545/2000 [01:36<00:27, 16.48it/s]\r 78%|███████▊  | 1553/2000 [01:36<00:25, 17.28it/s]\r 78%|███████▊  | 1561/2000 [01:37<00:25, 16.99it/s]\r 78%|███████▊  | 1569/2000 [01:37<00:26, 16.50it/s]\r 79%|███████▉  | 1577/2000 [01:38<00:25, 16.82it/s]\r 79%|███████▉  | 1585/2000 [01:38<00:27, 15.00it/s]\r 80%|███████▉  | 1593/2000 [01:39<00:26, 15.15it/s]\r 80%|████████  | 1601/2000 [01:39<00:26, 14.98it/s]\r 80%|████████  | 1609/2000 [01:40<00:28, 13.61it/s]\r 81%|████████  | 1617/2000 [01:41<00:27, 13.98it/s]\r 81%|████████▏ | 1625/2000 [01:41<00:25, 14.86it/s]\r 82%|████████▏ | 1633/2000 [01:42<00:25, 14.61it/s]\r 82%|████████▏ | 1641/2000 [01:42<00:24, 14.80it/s]\r 82%|████████▏ | 1649/2000 [01:43<00:21, 16.65it/s]\r 83%|████████▎ | 1657/2000 [01:43<00:19, 17.20it/s]\r 83%|████████▎ | 1665/2000 [01:43<00:19, 17.54it/s]\r 84%|████████▎ | 1673/2000 [01:44<00:16, 19.84it/s]\r 84%|████████▍ | 1681/2000 [01:44<00:15, 20.60it/s]\r 84%|████████▍ | 1689/2000 [01:45<00:16, 19.05it/s]\r 85%|████████▍ | 1697/2000 [01:45<00:18, 16.53it/s]\r 85%|████████▌ | 1705/2000 [01:46<00:17, 16.58it/s]\r 86%|████████▌ | 1713/2000 [01:46<00:17, 16.34it/s]\r 86%|████████▌ | 1721/2000 [01:47<00:19, 14.50it/s]\r 86%|████████▋ | 1729/2000 [01:47<00:17, 15.22it/s]\r 87%|████████▋ | 1737/2000 [01:48<00:17, 14.64it/s]\r 87%|████████▋ | 1745/2000 [01:48<00:16, 15.13it/s]\r 88%|████████▊ | 1753/2000 [01:49<00:16, 15.16it/s]\r 88%|████████▊ | 1761/2000 [01:50<00:15, 14.96it/s]\r 88%|████████▊ | 1769/2000 [01:50<00:14, 15.80it/s]\r 89%|████████▉ | 1777/2000 [01:50<00:13, 16.54it/s]\r 89%|████████▉ | 1785/2000 [01:51<00:12, 17.12it/s]\r 90%|████████▉ | 1793/2000 [01:51<00:11, 17.50it/s]\r 90%|█████████ | 1801/2000 [01:52<00:12, 16.52it/s]\r 90%|█████████ | 1809/2000 [01:52<00:11, 17.06it/s]\r 91%|█████████ | 1817/2000 [01:53<00:10, 16.90it/s]\r 91%|█████████▏| 1825/2000 [01:53<00:09, 17.74it/s]\r 92%|█████████▏| 1833/2000 [01:54<00:10, 16.09it/s]\r 92%|█████████▏| 1841/2000 [01:54<00:09, 16.91it/s]\r 92%|█████████▏| 1849/2000 [01:55<00:08, 17.02it/s]\r 93%|█████████▎| 1857/2000 [01:55<00:08, 16.40it/s]\r 93%|█████████▎| 1865/2000 [01:56<00:08, 15.94it/s]\r 94%|█████████▎| 1873/2000 [01:56<00:07, 17.66it/s]\r 94%|█████████▍| 1881/2000 [01:56<00:06, 19.24it/s]\r 94%|█████████▍| 1889/2000 [01:57<00:06, 17.50it/s]\r 95%|█████████▍| 1897/2000 [01:57<00:05, 17.74it/s]\r 95%|█████████▌| 1905/2000 [01:58<00:05, 17.18it/s]\r 96%|█████████▌| 1913/2000 [01:58<00:05, 15.81it/s]\r 96%|█████████▌| 1921/2000 [01:59<00:05, 13.82it/s]\r 96%|█████████▋| 1929/2000 [02:00<00:05, 14.03it/s]\r 97%|█████████▋| 1937/2000 [02:00<00:04, 13.95it/s]\r 97%|█████████▋| 1945/2000 [02:01<00:03, 14.42it/s]\r 98%|█████████▊| 1953/2000 [02:01<00:02, 16.65it/s]\r 98%|█████████▊| 1961/2000 [02:02<00:02, 16.19it/s]\r 98%|█████████▊| 1969/2000 [02:02<00:01, 17.42it/s]\r 99%|█████████▉| 1977/2000 [02:03<00:01, 15.81it/s]\r 99%|█████████▉| 1985/2000 [02:03<00:00, 18.45it/s]\r100%|█████████▉| 1993/2000 [02:03<00:00, 17.57it/s]\r100%|██████████| 2000/2000 [02:03<00:00, 16.14it/s]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nFirst 10 Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n:::\n\n\n```         \n100%|██████████| 2000/2000 [00:13<00:00, 144.93it/s]\n\nFirst 10 Predictions: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n```\n\n::: {#evaluate .cell cache='true' execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.metrics import classification_report\n# To evaluate the model's performance, we will create a classification report.\n\n# Extract true labels for the sampled data\ny_true = test_sample[\"label\"]\n\n# Define a function to evaluate performance\ndef evaluate_performance(y_true, y_pred):\n    \"\"\"Create and print the classification report\"\"\"\n    performance = classification_report(\n        y_true, y_pred,\n        target_names=[\"Negative Review\", \"Positive Review\"]\n    )\n    print(performance)\n\n# Evaluate the model performance\nevaluate_performance(y_true, y_pred)\n```\n:::\n\n\n# Classification Tasks That Leverage Embeddings\n\n::: {#create-embeddings .cell cache='true' execution_count=11}\n``` {.python .cell-code}\nfrom sentence_transformers import SentenceTransformer\n\n# Load model\nembedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=\"cpu\")\n\n# Convert text to embeddings\ntrain_embeddings = embedding_model.encode(train_sample[\"content\"], show_progress_bar=True)\ntest_embeddings = embedding_model.encode(test_sample[\"content\"], show_progress_bar=True)\n\ntrain_embeddings.shape\n```\n:::\n\n\n::: {#run-lr .cell cache='true' execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\n\n# Train a Logistic Regression on our train embeddings\nclf = LogisticRegression(random_state=42)\nclf.fit(train_embeddings, train_sample[\"label\"])\n\n# Predict previously unseen instances\ny_pred_embeddings = clf.predict(test_embeddings)\n\n# Evaluate the performance of the embedding-based classification\nevaluate_performance(test_sample[\"label\"], y_pred_embeddings)\n```\n:::\n\n\n# What if we don't use a classifier at all?\n\nInstead, we can average the embeddings per class and apply cosine similarity to predict which classes match the documents best:\n\n::: {#no-classifier .cell cache='true' execution_count=13}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Average the embeddings of all documents in each target label\ndf = pd.DataFrame(np.hstack([train_embeddings, np.array(train_sample[\"label\"]).reshape(-1, 1)]))\naveraged_target_embeddings = df.groupby(768).mean().values\n\n# Find the best matching embeddings between evaluation documents and target embeddings\nsim_matrix = cosine_similarity(test_embeddings, averaged_target_embeddings)\ny_pred_no_classifier = np.argmax(sim_matrix, axis=1)\n\n# Evaluate the model\nevaluate_performance(test_sample[\"label\"], y_pred_no_classifier)\n```\n:::\n\n\n# References\n\n",
    "supporting": [
      "index-copy_files"
    ],
    "filters": [],
    "includes": {}
  }
}